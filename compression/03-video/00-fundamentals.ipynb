{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video coding fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory requirements of PCM video\n",
    "\n",
    "* In RGB (PCM) video, each color pixel need at least 24 bpp (bits/pixel).\n",
    "\n",
    "* The memory requirements of RGB video are enormous. For example, an hour of $640\\times 480\\times 25$ Hz true-color of PCM video needs:\n",
    "\n",
    "\\begin{equation}\n",
    "    25\\frac{\\text{images}}{\\text{second}}\\times\n",
    "    640\\cdot 480\\frac{\\text{pixels}}{\\text{image}}\\times\n",
    "    24\\frac{\\text{bits}}{\\text{pixel}}=\n",
    "    184{.}320{.}000\\frac{\\text{bits}}{\\text{second}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    184{.}320{.}000\\frac{\\text{bits}}{\\text{second}} \\times\n",
    "    3{.}600\\frac{\\text{seconds}}{\\text{hour}} \\times\n",
    "    \\frac{1~\\text{G}}{1{.}024^3}\\times\n",
    "    \\frac{1~\\text{byte}}{8~\\text{bits}} \\approx\n",
    "    77~\\text{Gbytes}\n",
    "\\end{equation}\n",
    "\n",
    "* Video coding techniques should be used to compress this data. Most of these techniques are bases on Block-based Motion Estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of redundancy\n",
    "1. **Spatial redundancy**: Pixels are very similar in its neighborhood or tends to repeat textures.\n",
    "2. **Temporal redundancy**: Temporally adjacent images are typically very alike.\n",
    "3. **Visual redundancy**: Humans hardly perceive high spatial and temporal frequencies (we like more low frequencies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block-based ME (Motion Estimation)\n",
    "\n",
    "* Usually, only performed by the encoder.\n",
    "* ME removes temporal redundancy. A *predicted image* can be\n",
    "  encoded as the difference between it and another image called\n",
    "  *prediction image* which is a motion compensated projection of\n",
    "  one or more images named *reference images*. ME tries to\n",
    "  generate *residue images* as close as possible to the null\n",
    "  images.\n",
    "* Usually, the reference image/s is/are divided in blocks of\n",
    "  $16\\times 16$ pixels called *macroblocks*.\n",
    "* Each reference block is searched in the predicted image and the\n",
    "  best match is indicated by mean of a *motion vector*.\n",
    "* Depending on the success of the search and the number of\n",
    "  reference images, the macroblocks are classified into:\n",
    "  + **I (intra)**: When the compression of residue block generates more\n",
    "    bits than the original (predicted) one.\n",
    "  + **P (predicted)**: When it is better to compress the residue block and\n",
    "    there is only one reference macroblock.\n",
    "  + **B (bidirectionally predicted)**: The same, but if we have two reference macroblocks.\n",
    "  + **S (skipped)**: When the energy of the residue block is\n",
    "    smaller than a given threshold.\n",
    "* I-pictures are composed of I macroblocks, only.\n",
    "* P-pictures do not have B macrobocks.\n",
    "* B-pictures can have any type of macroblocks.\n",
    "\n",
    "<img src=\"00-fundamentals/macroblocks.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-pixel accuracy\n",
    "\n",
    "* The motion estimation can be carried out using integer pixel\n",
    "  accuracy or a fractional (sub-) pixel accuracy.\n",
    "* For example, in MPEG-1, the motion estimation can have up to 1/2\n",
    "  pixel accuracy. A bi-linear interpolator is used:\n",
    "\n",
    "<img src=\"00-fundamentals/interpolation.svg\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching criteria (similitude between macroblocks)\n",
    "\n",
    "* Let $a$ and $b$ the macroblocks which we want to compare. Two\n",
    "  main distortion metrics are commonly used:\n",
    "  \n",
    "  + **Mean Square Error**:\n",
    "  \n",
    "    \\begin{equation}\n",
    "      \\frac{1}{16\\times 16}\\sum_{i=1}^{16}\\sum_{j=1}^{16}(a_{ij}-b_{ij})^2\n",
    "    \\end{equation}\n",
    "    \n",
    "  + **Mean Absolute Error**:\n",
    "  \n",
    "    \\begin{equation}\n",
    "      \\frac{1}{16\\times 16}\\sum_{i=1}^{16}\\sum_{j=1}^{16}|a_{ij}-b_{ij}|\n",
    "    \\end{equation}\n",
    "\n",
    "* These similitude measures are used only by the\n",
    "  compressor. Therefore, any other one with similar effects (such as\n",
    "  the error variance or the error entropy) could be used also.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching strategies\n",
    "\n",
    "* Only performed by the compressor.\n",
    "\n",
    "    + **Full search**: All the possibilities are\n",
    "    checked. Advantage: the best compression. Disadvantage: CPU\n",
    "    killer.\n",
    "    \n",
    "    <img src=\"00-fundamentals/full_search.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "    + ** Logaritmic search**: It is a version of the full search\n",
    "    algorithm where the macro-blocks and the search area are\n",
    "    sub-sampled. After finding the best coincidence, the resolution of\n",
    "    the macro-block is increased in a power of 2 and the previous\n",
    "    match is refined in a search area of $\\pm 1$, until the maximal\n",
    "    resolution (even using subpixel accuracy) is reached.\n",
    "    \n",
    "    + **Telescopic search**: Any of the previously described\n",
    "    techniques can be speeded up if the searching area is\n",
    "    reduced. This can be done supposing that the motion vector of the\n",
    "    same macro-block in two consecutive images is similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The GOP (Group Of Pictures) concept\n",
    "\n",
    "* The temporal redundancy is exploited by blocks of images called\n",
    "  GOPs. This means that a GOP can be decoded independently of the rest\n",
    "  of GOPs. Here an example:\n",
    "  \n",
    "<img src=\"00-fundamentals/GOPs.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lossy predictive video coding\n",
    "\n",
    "* Let $V_i$ the i-th image of the video sequence and $V^{[q]}_i$ and\n",
    "approximation of $V_i$ with quality $q$ (most video compressors are\n",
    "lossy). In this context, an hybrid video codec (t+2d) (\"t\" means\n",
    "  ''temporal redundancy supression'', and 2d ``spatial redundancy\n",
    "  supression'') has the following structure:\n",
    "\n",
    "<img src=\"00-fundamentals/MC-lossy-DPCM.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCTF (Motion Compensated Temporal Filtering)\n",
    "\n",
    "* This is a DWT where the input samples are the original video\n",
    "  images and the output is a sequence of residue images.\n",
    "  \n",
    "<img src=\"00-fundamentals/MCTF.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t+2d vs. 2d+t vs. 2d+t+2d\n",
    "\n",
    "* **t+2d**: The sequence of images is decorrelated first\n",
    "  along the time (t) and the residue images are compressed, exploiting\n",
    "  the remaining spatial (2d) redundancy. Examples: MPEG* and H.26*\n",
    "  codecs (except H.264/SVC).\n",
    "  \n",
    "* **2d+t**: The spatial (2d) redudancy is explited first\n",
    "  (using typically the DWT) and next the coefficients are decorrelated\n",
    "  along the time (t). To date this has only been experimental setup\n",
    "  because most transformed domains are not invariant to the\n",
    "  displacement.\n",
    "  \n",
    "* **2d+t+2d**: The fist step creates a Laplacian Pyramid\n",
    "  (2d), which is invariant to the displacement. Next, each level of\n",
    "  the pyramid is decorrelated along the time (t) and finally, the\n",
    "  remaining spatial redundancy is removed (2d). Example: H.264/SVC.\n",
    "\n",
    "<img src=\"00-fundamentals/H264-S-SVC.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deblocking filtering\n",
    "\n",
    "* Block based video encoders (those than use block-based temporal\n",
    "  decorrelation) improve their performance if a deblocking filter in\n",
    "  used to create the quantized prediction predictions.\n",
    "  \n",
    "<img src=\"00-fundamentals/350px-Deblock1.jpg\" style=\"width: 800px;\"/>\n",
    "\n",
    "*The low-pass filter is applied only on the block boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bit-rate allocation\n",
    "\n",
    "* Under a constant quantization level (constant video quality),\n",
    "  the number of bits that each compressed image needs depends on the\n",
    "  image content. Example:\n",
    "\n",
    "<img src=\"00-fundamentals/closed-loop-1_ir.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* The encoder must decide how much information will be stored in\n",
    "  each residue image, taking into account that this image can serve as\n",
    "  a reference for other images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality scalability\n",
    "\n",
    "<img src=\"00-fundamentals/quality-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* Ideal for remote visualization environments.\n",
    "\n",
    "* In reversible codecs, $V_i^{[0]}=V_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal scalability\n",
    "\n",
    "<img src=\"00-fundamentals/temporal-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* It holds that:\n",
    "\\begin{equation}\n",
    "  V^{t}=\\{V_{2^t\\times i};~0\\le i < \\frac{\\text{#}V}{2^t}\\}=\\{V_{2i}^{t-1};~0\\le i < \\frac{\\text{#}V^{t-1}}{2}\\},\n",
    "\\end{equation}\n",
    "where $\\text{#}V$ is the number of pixtures in $V$ and $t$ denotes the\n",
    "Temporal Resolution Level (TRL).\n",
    "\n",
    "* Notice that $V=V^{0}$.\n",
    "\n",
    "* Useful for fast random access."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial scalability\n",
    "\n",
    "<img src=\"00-fundamentals/spatial-scalability.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* Useful for low-resolution devices.\n",
    "\n",
    "* In reversible codecs, $V_i=V_i^{<0>}$ and $V_i^{<s>}$ has a\n",
    "  $\\frac{Y}{2^s}\\times \\frac{X}{2^s}$ resolution, where $X\\times Y$ is\n",
    "  the resolution of $V_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
