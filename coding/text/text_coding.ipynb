{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text compression\n",
    "\n",
    "## Why?\n",
    "\n",
    "* After the digitalization of any signal we get a sequence $s[]$\n",
    "  of samples that represent the signal $s$ with more or less fidelity.\n",
    "  \n",
    "* $s[]$ is encoded using PCM (Pulse Code Modulation), in which\n",
    "  every sample is represented with the same number of bits. For\n",
    "  example, in a CD we have a data-rate of\n",
    "  \n",
    "  $$\n",
    "    (16+16)\\frac{\\text{bits}}{\\text{sample}}\\times\n",
    "    44{.}100\\frac{\\text{samples}}{\\text{second}}=\n",
    "    1{.}411{.}200\\frac{\\text{bits}}{\\text{second}}.\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources of redundancy in signals\n",
    "\n",
    "* In general, signals has different types of redundancy:\n",
    "\n",
    "    + **Statistical redundancy**: It can be removed using\n",
    "    probabilistic models of the signal producing lossless codecs. The\n",
    "    codecs are also known as *text codecs*.\n",
    "    \n",
    "    + **Spatial/temporal redundancy**: It can be removed using\n",
    "    spatial/temporal models of the signal and produces also lossless\n",
    "    codecs.\n",
    "    \n",
    "    + **Psychological redundancy**: Some information that\n",
    "    signal carry can not be perceived by humans. This kind of\n",
    "    pseudo-redundancy is removed normally by means of quantization,\n",
    "    producing lossy codecs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symbols, runs, strings, code-words and code-streams\n",
    "\n",
    "* In the context of statistical coding, each sample of $s[]$ is\n",
    "  called a *symbol*.\n",
    "  \n",
    "* Depending on the type of statistical relationship among\n",
    "  symbols, we will speak also about *strings* when we process\n",
    "  more than one symbol and about *runs* when all the symbols are\n",
    "  the same in a string.\n",
    "  \n",
    "* In any case, the output of the encoder is a sequence of\n",
    "  code-words that all together generates a *code-stream*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Run-length encoding\n",
    "\n",
    "* RLE (Run Length Encoding) is a technique that removes the data\n",
    "  redundancy produced by the repetition of symbols. Example:\n",
    "  ```\n",
    "  aaaaa <-> 5a\n",
    "  ```\n",
    "  \n",
    "* There are several versions of RLE codecs, which are different in\n",
    "  the size of the source alphabet or the maximal/minimal length that\n",
    "  the runs can take."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1 N-ary run length encoding\n",
    "\n",
    "RLE for N-ary alphabets (alphabets of size N), where typically, N=256.\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "1. While there are symbols to encode:\n",
    "    1. Let $s$ the next symbol.\n",
    "    2. Read the next $n$ consecutive symbols equal to $s$.\n",
    "    3. Write the pair $ns$.\n",
    "\n",
    "#### Decoder\n",
    "\n",
    "1. While there are $ns$ pairs to decode:\n",
    "    1. Write $n$-times the symbol $s$.\n",
    "    \n",
    "#### Example\n",
    "\n",
    "Runs:\n",
    "```\n",
    "aaaabbbbbaaaaaabbbbbbbcccccc\n",
    "```\n",
    "are encoded as:\n",
    "```\n",
    "4a5b6a7b6c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Binary run length encoding\n",
    "\n",
    "* It is not necessary to indicate the next symbol\n",
    "  (only the length) because if a run ends, the other (possible) symbol\n",
    "  start with the next run.\n",
    "  \n",
    "#### Encoder\n",
    "\n",
    "1. Let $s\\leftarrow$ \\texttt{0}.\n",
    "2. While there are bits to encode:\n",
    "    1. Read the next $n$ consecutive bits equal to $s$.\n",
    "    2. Write $n$.\n",
    "    3. $s\\leftarrow (s+1)~\\text{modulus}~2$.\n",
    "    \n",
    "#### Decoder\n",
    "\n",
    "1. Let $s\\leftarrow$ \\texttt{0}.\n",
    "2. While there are items $n$ to decode:\n",
    "    1. Write $n$ bits equal to $s$.\n",
    "    2. $s\\leftarrow (s+1)~\\text{modulus}~2$.\n",
    "\n",
    "#### Example\n",
    "\n",
    "Runs:\n",
    "```\n",
    "0000111110000001111111000000\n",
    "```\n",
    "are encoded as::\n",
    "```\n",
    "4 5 6 7 6\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 [MPN-5 run length encoding](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=held+data+compression+techniques+applications&btnG=)\n",
    "\n",
    "* Created by Microcom Inc. for the MNP (Microcom Networking\n",
    "  Protocol) 5.\n",
    "\n",
    "#### Codec\n",
    "\n",
    "* The behavior of the codec can be easily defined with the\n",
    "  following examples:\n",
    "  \n",
    "```\n",
    "Input     Output\n",
    "--------- ---------\n",
    "ab        ab\n",
    "aab       aab\n",
    "aaab      aaa0b\n",
    "aaaab     aaa1b\n",
    "aaaaab    aaa2b\n",
    ":         :\n",
    "a^nb      aaa(n-3)b\n",
    "```\n",
    "\n",
    "#### Example\n",
    "\n",
    "Runs:\n",
    "```\n",
    "aaaabbbbbaaaaaabbbbbbbcccccc\n",
    "```\n",
    "are encoded as:\n",
    "```\n",
    "aaa1bbb2aaa3bbb4\n",
    "```\n",
    "\n",
    "#### Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"text_coding/lena-gray.png\" style=\"width: 400px;\"/>\n",
    "<img src=\"text_coding/peppers-gray.png\" style=\"width: 400px;\"/>\n",
    "<img src=\"text_coding/boats.png\" style=\"width: 400px;\"/>\n",
    "<img src=\"text_coding/zelda.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `rle`, compute the compression ratio of each image as\n",
    "\n",
    "$$\n",
    "\\gamma = \\frac{X}{Y}\n",
    "$$\n",
    "\n",
    "where $X$ is the size of the input (the sequence of symbols) and $Y$\n",
    "the size of the output (the code-stream), and populate:\n",
    "```\n",
    "Codec | lena boats pepers zelda Average\n",
    "------+--------------------------------\n",
    "  rle | ....  ....   ....  ....    ....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.4 [Burrows-Wheeler transform](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Burrows+M%2C+Wheeler+DJ%3A+A+Block+Sorting+Lossless+Data+Compression+Algorithm.&btnG=)\n",
    "\n",
    "* BWT (Burrows-Wheeler Transform) is an algorithm that inputs\n",
    "  a string and outputs:\n",
    "  1. A different string with the same symbols (with longer runs),\n",
    "    but with a different order.\n",
    "  2. An index.\n",
    "  \n",
    "  \n",
    "* There is an inverse transform that, using the output of the\n",
    "  forward transform, recover the original string.\n",
    "  \n",
    "* The transformed string tends to have longer runs.\n",
    "\n",
    "* The length of the runs in proportional to the correlation\n",
    "  between the symbols and the length of the input.\n",
    "  \n",
    "### Forward transform\n",
    "\n",
    "Let $B$ the block-size in symbols:\n",
    "\n",
    "1. Read $B$ symbols.\n",
    "2. Build a square matrix of size $B\\times B$ where the first row is\n",
    "  the original sequence, the second one is the same sequence but\n",
    "  cyclically shifted one symbol to the left, and so on ...\n",
    "3. Sort lexicographically the matrix by rows.\n",
    "4. Search in the last column the row in which the first symbol of\n",
    "  the original sequence it is found. This is the index $i$.\n",
    "5. Output $i$ and the last column $O[]$.\n",
    "\n",
    "#### Encoding example\n",
    "<img src=\"text_coding/BWT_example.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "### Inverse transform\n",
    "\n",
    "1. Sort $O[]$ over $S[]$.\n",
    "2. Compute $T[]$ where if $S[j]=O[l]$ (being $l$ the first symbol\n",
    "  of $O[]$ that matches this condition), then $T[j]=l$. Notice that\n",
    "  all of symbols of $T[]$ have to be different.\n",
    "3. Let $k\\leftarrow i$.\n",
    "4. Execute $B$ times:\n",
    "    1. Output $O[k]$.\n",
    "    2. $k\\leftarrow T[k]$.\n",
    "    \n",
    "#### Decoding example\n",
    "<img src=\"text_coding/BWT_example_decod.svg\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 baaaaaabbabaacaab\n",
      "ababcbababaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "# https://gist.github.com/dmckean/9723bc06254809e9068f\n",
    "\n",
    "def bwt_encode(s):\n",
    "    n = len(s)\n",
    "    m = sorted([s[i:n]+s[0:i] for i in range(n)])\n",
    "    I = m.index(s)\n",
    "    L = ''.join([q[-1] for q in m])\n",
    "    return (I, L)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "def bwt_decode(I, L):\n",
    "    n = len(L)\n",
    "    X = sorted([(i, x) for i, x in enumerate(L)], key=itemgetter(1))\n",
    "\n",
    "    T = [None for i in range(n)]\n",
    "    for i, y in enumerate(X):\n",
    "        j, _ = y\n",
    "        T[j] = i\n",
    "\n",
    "    Tx = [I]\n",
    "    for i in range(1, n):\n",
    "        Tx.append(T[Tx[i-1]])\n",
    "\n",
    "    S = [L[i] for i in Tx]\n",
    "    S.reverse()\n",
    "    return ''.join(S)\n",
    "\n",
    "index, encoded = bwt_encode('ababcbababaaaaaaa')\n",
    "print (index, encoded)\n",
    "decoded = bwt_decode(index, encoded)\n",
    "print (decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. String encoding\n",
    "\n",
    "### How it works?\n",
    "\n",
    "* We replace strings by code-words of less length.\n",
    "* Strings are searched in a dictionary and the sequence of positions of the strings in the dictionary form the code-strem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1 LZ77 [[J. Ziv and A. Lempel, 1977]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Ziv+Lempel+universal+sequential+data+compression+1977&btnG=)\n",
    "\n",
    "* In 1977, Jacov Ziv and Abraham Lempel propose the LZ77 algorithm.\n",
    "* In the eighties, a branch of LZ77 known as LZSS and is\n",
    "  implemented by Haruyasu Yoshizaki in the program LHARC, discovering\n",
    "  the possibilities of the LZ77 encoding.\n",
    "* After that, a large number of text compressors have been based\n",
    "  on the LZ77 idea (or a variation of it). Some of the most famous\n",
    "  are: `ARJ`, `RAR`, `gzip` and `7z`.\n",
    "* LZ77 processes a sequence of symbols using the structure:\n",
    "\n",
    "<img src=\"text_coding/LZ77.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "* The dictionary and the look-ahead buffer have a fixed size and\n",
    "  can be considered as a sliding window, where the input of a new\n",
    "  symbol generates the output of the oldest one, which becomes the\n",
    "  newest symbol of the dictionary.\n",
    "  \n",
    "#### Encoder\n",
    "\n",
    "1. Let $I$ the length of the dictionary and $J$ the length of the\n",
    "  buffer.\n",
    "2. Input the first $J$ symbols in the buffer.\n",
    "3. While the input is not exhausted:\n",
    "    1. Let $i$ the position in the dictionary of the first $j$\n",
    "    symbols of the buffer and $k$ the symbol that makes that $j$ can\n",
    "    not be larger.\n",
    "    2. Output $ijk$.\n",
    "    3. Input the next $j+1$ in the buffer.\n",
    "    \n",
    "#### Decoder\n",
    "\n",
    "1. While the code-words $ijk$ are not exhausted:\n",
    "    1. Output the $j$ symbols extracted from the position $i$ in the\n",
    "    dictionary.\n",
    "    2. Output $k$.\n",
    "    3. Introduce all the decoded symbols into the buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "<img src=\"text_coding/LZ77_encoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"text_coding/LZ77_decoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "* Parameters $I$ and $J$ control the performance\n",
    "  of the algorithm. They should be large enough to guarantee the\n",
    "  matching of long strings, but should keep small in order to reduce\n",
    "  the number of bits of the code-words $ijk$. Typical sizes are:\n",
    "  $\\log_2(I)=12.0$ and $\\log_2(J)=4.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab\n",
    "To-do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 LZ78 [[J. Ziv and A. Lempel, 1978]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Ziv+Lempel+1978&btnG=)\n",
    "\n",
    "* In 1978, Ziv and Lempel published the LZ78 algorithm.\n",
    "\n",
    "* LZ89 represents the dictionary in a recursive way with the idea\n",
    "  of improving the search of the strings in the dictionary. Now, each\n",
    "  entry in the dictionary is a pair $wk$, where $w$ is a pointer to\n",
    "  the dictionary and $k$ is a symbol. In fact, each entry $wk$\n",
    "  represents the string that results from the concatenation of string\n",
    "  $w$ and $k$, where $w$ can be recursively computed as we have found\n",
    "  $wk$.\n",
    "  \n",
    "* We will denote \\textit{string}$(w)$ to the string that $w$\n",
    "  represents.\n",
    "  \n",
    "* The empty string is obtained by \\textit{string}$(0)$.\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "1. $w\\leftarrow 0$.\n",
    "2. While the input is not exhausted:\n",
    "    1. $k\\leftarrow$ next input symbol.\n",
    "    2. If $wk$ is found in the dictionary, then:\n",
    "        1. $w\\leftarrow$ address of $wk$ in the dictionary.\n",
    "    3. Else:\n",
    "        1. Output $wk$.\n",
    "        2. Insert $wk$ in the dictionary.\n",
    "        3. $w\\leftarrow 0$.\n",
    "        \n",
    "#### Decoder\n",
    "\n",
    "1. While the input is not exhausted:\n",
    "    1. Input $wk$.\n",
    "    2. Output $\\text{string}(w)$.\n",
    "    3. Output $k$.\n",
    "    4. Insert $wk$ in the dictionary.\n",
    "    \n",
    "#### Example\n",
    "\n",
    "<img src=\"text_coding/LZ78_encoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"text_coding/LZ78_decoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.3 LZW [[T.A. Welch, 1984]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Terry+Welch+1984&btnG=)\n",
    "\n",
    "* In 1984 Terry A. Welch proposes the LZW algorithm,\n",
    "  which is an improved version of the LZ89 algorithm that does not\n",
    "  writes raw symbols ($k$) to the code-stream.\n",
    "\n",
    "* LZW was selected as encoding engine for the GIF (Graphics\n",
    "  Interchange Format), and for the compressor `compress`.\n",
    "  \n",
    "* The dictionary is initially filled with the $2^k$ possible\n",
    "  symbols (*roots*), that are stored in entries $0\\cdots255$.\n",
    "  \n",
    "#### Encoder\n",
    "\n",
    "1. $w\\leftarrow$ next input symbol.\n",
    "2. While the input is not exhausted:\n",
    "    1. $k\\leftarrow$ next input symbol.\n",
    "    2. If $wk$ is found in the dictionary, then:\n",
    "        1. $w\\leftarrow$ address of $wk$ in the dictionary.\n",
    "    3. Else:\n",
    "        1. Output $\\leftarrow w$.\n",
    "        2. Insert $wk$ in the dictionary.\n",
    "        3. $w\\leftarrow k$.\n",
    "\n",
    "#### Decoder\n",
    "\n",
    "1. $code\\leftarrow$ first input code-word.\n",
    "2. Output $code$.\n",
    "3. $old\\_code\\leftarrow code$.\n",
    "4. While the input is not exhausted:\n",
    "    1. $code\\leftarrow$ next input code-word.\n",
    "    2. $w\\leftarrow old\\_code$.\n",
    "    3. If $code$ is found in the dictionary, then:\n",
    "        1. Output string$(code)$.\n",
    "    4. Else:\n",
    "        1. Output string$(w)$.\n",
    "        2. Output $k$.\n",
    "    5. $k\\leftarrow$ first symbol of the last output.\n",
    "    6. Insert $wk$ in the dictionary.\n",
    "    7. $old\\_code\\leftarrow code$.\n",
    "    \n",
    "#### Example\n",
    "\n",
    "<img src=\"text_coding/LZW_encoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "<img src=\"text_coding/LZW_decoding_example.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Symbol encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works?\n",
    "\n",
    "* We can compress if each symbol is translated by code-words and,\n",
    "  in average, the lengths of the code-words are smaller than the\n",
    "  length of the symbols.\n",
    "  \n",
    "* The encoder and the decoder have a probabilistic model $M$ which\n",
    "  says to the variable-length encoder ($C$)/decoder($C^{-1}$) the\n",
    "  probability $p(s)$ of each symbol $s$.\n",
    "  \n",
    "<img src=\"text_coding/compresion_entropica.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "* The most probable symbols are represented by the shorter\n",
    "  code-words and viceversa.\n",
    "  \n",
    "### Bits\n",
    "\n",
    "* Data is the representation of the information.\n",
    "\n",
    "* Lossless data compression uses a shorter representation of the\n",
    "  information.\n",
    "  \n",
    "* By definition, a bit of data stores a bit of information if and\n",
    "  only if it represents the occurrence of an equiprobable event (an\n",
    "  event that can be true or false with the same probability).\n",
    "  \n",
    "* By definition, a symbol $s$ with probability $p(s)$ stores\n",
    "\n",
    "\\begin{equation}\n",
    "  I(s)=-\\log_2 p(s) \\tag{Eq:symbol_information}\n",
    "\\end{equation}\n",
    "  \n",
    "  bits of information.\n",
    "\n",
    "* The length of the code-word depends on the probability as:\n",
    "\n",
    "<img src=\"text_coding/prob_vs_long.svg\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Entropy\n",
    "\n",
    "* The entropy $H(S)$ measures the amount of information per\n",
    "  symbol that a source of information $S$ produces, in average, i.e.\n",
    "  \n",
    "\\begin{equation}\n",
    "  H(S) = \\frac{1}{N}\\sum_{s=1}^{N} p(s)\\times I(s)\n",
    "\\end{equation}\n",
    "\n",
    "  bits-of-information/symbol, where $N$ is the size of the source\n",
    "  alphabet (number of different symbols)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.1 Universal coding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
