{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio compression fundamentals\n",
    "\n",
    "### How big is audio data?\n",
    "\n",
    "* **Mobile**: up to $13$ Kbps.\n",
    "* **(Terrestial) telephony**: $64$ Kbps.\n",
    "* **CD quality**: $1.441$ Mbps.\n",
    "* **AC-3 (Dolby Digital)**: up to $6.144$ Mbps.\n",
    "* **DTS**: up to $1509.75$ Kbps.\n",
    "\n",
    "### How to reduce the bit-rate?\n",
    "\n",
    "* Reducing the sampling rate (less bandwidth).\n",
    "* Reducing the number of channels.\n",
    "* Reducing the bits/sample (quantization).\n",
    "* Using audio compression.\n",
    "\n",
    "### What is an audio codec (COder/DECoder)?\n",
    "\n",
    "```\n",
    "PCM   +---------+        +---------+ PCM\n",
    "----->| Encoder |------->| Decoder |----->\n",
    "audio +---------+ stream +---------+ audio'\n",
    "\n",
    "              audio != audio'\n",
    "                (usually)\n",
    "```\n",
    "\n",
    "### Typical encoder steps\n",
    "\n",
    "1. **Overlaped subband analysis** (usually with [MDCT](http://en.wikipedia.org/wiki/Modified_discrete_cosine_transform} (Modified\n",
    "   Discrete Cosine Transform)). Goes from the temporal to a frequency\n",
    "   domain.\n",
    "  \n",
    "2. **Quantization**. Basically, removes pure signals of low amplitude\n",
    "   but taking also into account the SAM (pSycho Acoustic Model) of the\n",
    "   HAS (Human Auditory System). Noise use to be of low power!\n",
    "   \n",
    "3. [**Entropy coding**](https://github.com/vicente-gonzalez-ruiz/teaching/blob/master/coding/text/text_coding.ipynb).\n",
    "\n",
    "###Â Overlaped processing\n",
    "\n",
    "```\n",
    "0              N-1            2N-1            3N-1\n",
    "+---------------+---------------+---------------+ s[n]\n",
    "<--------Transform Step--------->\n",
    "                <---------Transform Step-------->\n",
    "```\n",
    "\n",
    "* Each transform step inputs $2N$ samples and outputs $N$ MDCT\n",
    "  coeficients.\n",
    "  \n",
    "* $N$ can vary depending on the characteristics of the sound. For\n",
    "  \\emph{complex} sounds without clear armonics (such as a plosive sound),\n",
    "  shortened windows improve the performance. For \\emph{simple} sounds\n",
    "  (such as a music instrument), large windows are better.\n",
    "  \n",
    "### MDCT\n",
    "\n",
    "* Equivalent to apply a [bank of $N$ filters](http://en.wikipedia.org/wiki/Filter_bank).\n",
    "\n",
    "* Determines the correlation between a set of $2N$ numbers\n",
    "  (samples) and $N$\n",
    "  [orthogonal](http://en.wikipedia.org/wiki/Orthogonality) (two\n",
    "  functions/signals are orthogonal if it is impossible to obtain one\n",
    "  of them by means of the other.) [cosine functions](http://guru.multimedia.cx/mdct/). \n",
    "  Therefore, at the input of the DCT there are $2N$ samples and at the output,\n",
    "  $N$ coefficients.\n",
    "  \n",
    "* MDCT coefficients $S[w]$ of the PCM samples $s[n]$ are\n",
    "  defined as:\n",
    "  \\begin{equation}\n",
    "    S[w] = \\sum_{n=0}^{2N-1}s[n]cos\\Big[\\frac{\\pi}{N}(n+\\frac{1}{2}+\\frac{N}{2})(w+\\frac{1}{2})\\Big].\n",
    "    \\label{eq:MDCT}\n",
    "  \\end{equation}\n",
    "  \n",
    "## SAM (pSycho Acoustic Model) of the HAS (Human Auditory System)\n",
    "\n",
    "### ATH (Absolute Threshold of Hearing) model [[Terhardt, 1979]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Calculating+virtual+pitch+Terhardt&btnG=)\n",
    "\n",
    "<img src=\"00-fundamentals/ATHM.svg\" style=\"width: 800px;\"/>\n",
    "\n",
    "* This means that humans ear better those sounds that contains\n",
    "  audio signals with frequencies that ranges between 3 KHz\n",
    "  and 4 KHz.\n",
    "  \n",
    "### Frequency resolution and simultaneous masking\n",
    "\n",
    "* The HAS has a limited frequency resolution. Psychoacoustic\n",
    "  experiments have demonstrated that the audible frequencies can be\n",
    "  grouped into \\href{../../../Perception/Auditive_perception/index.html#x1-50004}{barks}.\n",
    "\n",
    "* Each bark defines the group of frequencies that excite the same\n",
    "  cochlear area, i.e., those frequencies that can be masked by the\n",
    "  tone with the highest energy (in that bark).\n",
    "  \n",
    "### Temporal masking\n",
    "\n",
    "* The human auditory system has inertia:\n",
    "  \\href{../../../Perception/Auditive_perception/index.html#x1-70006}{sounds\n",
    "    are not instantly perceived and remains after they are disapered}.\n",
    "    \n",
    "### Channel coupling\n",
    "\n",
    "* Most of the time, similar sounds are transported in the channels\n",
    "  of a non-mono audio signal. Channel coupling decreases inter-channel\n",
    "  redundancy, usually, using prediction techniques.\n",
    "\n",
    "### Quantization\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
