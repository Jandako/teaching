{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image coding fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.degeneratestate.org/posts/2016/Oct/23/image-processing-with-numpy/\n",
    "# http://www.scipy-lectures.org/packages/scikit-image/\n",
    "# https://www.safaribooksonline.com/library/view/programming-computer-vision/9781449341916/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.hpca.ual.es/~vruiz/images/Homer.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Homer.png](./Homer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo `wc -c < Homer.png` bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!convert -quality 40 Homer.png Homer.jp2\n",
    "# Note: in OSX, install imagemagick with: \"brew install imagemagick --with-openjpeg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Homer.jp2](./Homer.jp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo `wc -c < Homer.jp2` bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageOps\n",
    "orig = Image.open('Homer.png')\n",
    "comp = Image.open('Homer.jp2')\n",
    "diff = ImageChops.subtract(orig, comp)\n",
    "diff = ImageOps.equalize(diff)\n",
    "diff.save('diff.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![diff.png](./diff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image compressors exploit *spatial redundancy* to achieve better bit-rate/distortion ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 00-fundamentals/\n",
    "!wget http://www.hpca.ual.es/~vruiz/images/lena.png\n",
    "!convert lena.png lena.ppm\n",
    "!pnmcut -top 250 -right 350 -width 40 -height 40 < lena.ppm | pnmtopng > lena-cut.png\n",
    "!fig2dev -L png -m 4 correlacion_lena.fig > correlacion_lena.png\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/correlacion_lena.png\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial redundancy generates that neighbor pixels have similar colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luminance and chrominance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Chrominance](https://en.wikipedia.org/wiki/Chrominance) (or chroma) is the signal used in video systems to convey the color information of the picture or a video. It was defined to add the color signal to the black and white one. Thus, the same signal, composed by two different subsignals: Y and UV that can be isolated by filtering, was compatible with both, black and white (which only used Y) and color ones (that used YUV).\n",
    "\n",
    "Later, in digital video, the YUV color domain was called the [YCrCb color domain](https://en.wikipedia.org/wiki/YCbCr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral (color) redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{RGB}$ domain is more redundant than the [$\\text{Y'UV}$ domain](https://en.wikipedia.org/wiki/YUV):\n",
    "\n",
    "\\begin{equation}\n",
    "    \\left(\n",
    "      \\begin{array}{c}\n",
    "        \\text{Y'}\\\\\n",
    "        \\text{U}\\\\\n",
    "        \\text{V}\n",
    "      \\end{array}\n",
    "    \\right) =\n",
    "    \\left(\n",
    "      \\begin{array}{rrr}\n",
    "          0,299 & 0,587 & 0,144 \\\\\n",
    "          -0.14713 & -0.28886 &  0.436 \\\\\n",
    "          0.615   & -0.51499 & -0.10001\n",
    "      \\end{array}\n",
    "    \\right)\n",
    "    \\left(\n",
    "      \\begin{array}{c}\n",
    "        \\text{R}\\\\\n",
    "        \\text{G}\\\\\n",
    "        \\text{B}\n",
    "      \\end{array}\n",
    "    \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\left(\n",
    "      \\begin{array}{c}\n",
    "        \\text{R}\\\\\n",
    "        \\text{G}\\\\\n",
    "        \\text{B}\n",
    "      \\end{array}\n",
    "    \\right) =\n",
    "    \\left(\n",
    "      \\begin{array}{rrr}\n",
    "          1 &  0       &  1.13983 \\\\\n",
    "          1 & -0.39465 & -0.58060 \\\\\n",
    "          1 &  2.03211 &  0\n",
    "      \\end{array}\n",
    "    \\right)\n",
    "    \\left(\n",
    "      \\begin{array}{c}\n",
    "        \\text{Y'}\\\\\n",
    "        \\text{U}\\\\\n",
    "        \\text{V}\n",
    "      \\end{array}\n",
    "    \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used, for example, in [JPEG](https://en.wikipedia.org/wiki/JPEG)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://www.hpca.ual.es/~vruiz/images/san-diego.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![san-diego.png](./san-diego.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "from scipy.stats import entropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RGB = misc.imread('san-diego.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(24,16))\n",
    "plt.imshow(RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = RGB.copy()\n",
    "R[:,:,1] = 0\n",
    "R[:,:,2] = 0\n",
    "G = RGB.copy()\n",
    "G[:,:,0] = 0\n",
    "G[:,:,2] = 0\n",
    "B = RGB.copy()\n",
    "B[:,:,0] = 0\n",
    "B[:,:,1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,16))\n",
    "\n",
    "a = fig.add_subplot(1,3,1) # Rows, cols, subfigure\n",
    "R_histo = np.histogram(RGB[:,:,0], bins=256)[0]\n",
    "R_entropy = entropy(R_histo, base=2)\n",
    "a.set_title(\"entropy(R) = \" + str(R_entropy))\n",
    "imgplot = plt.imshow(R)\n",
    "\n",
    "a = fig.add_subplot(1,3,2)\n",
    "G_histo = np.histogram(RGB[:,:,1], bins=256)[0]\n",
    "G_entropy = entropy(G_histo, base=2)\n",
    "a.set_title(\"entropy(G) = \" + str(G_entropy))\n",
    "imgplot = plt.imshow(G)\n",
    "\n",
    "a = fig.add_subplot(1,3,3)\n",
    "B_histo = np.histogram(RGB[:,:,2], bins=256)[0]\n",
    "B_entropy = entropy(B_histo, base=2)\n",
    "a.set_title(\"entropy(B) = \" + str(B_entropy))\n",
    "imgplot = plt.imshow(B)\n",
    "plt.show()\n",
    "\n",
    "# See https://stackoverflow.com/questions/3584805/in-matplotlib-what-does-the-argument-mean-in-fig-add-subplot111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total entropy = {}'.format(R_entropy + G_entropy + B_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "components = ('r','g','b')\n",
    "histr = [None for col in components]\n",
    "for i,com in enumerate(components):\n",
    "    histr[i] = cv2.calcHist([RGB],[i],None,[256],[0,256])\n",
    "    plt.plot(histr[i], color = com)\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43983265/rgb-to-yuv-conversion-and-accessing-y-u-and-v-channels\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lut_u():\n",
    "    return np.array([[[i,255-i,0] for i in range(256)]],dtype=np.uint8)\n",
    "\n",
    "def make_lut_v():\n",
    "    return np.array([[[0,255-i,i] for i in range(256)]],dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_U, lut_V = make_lut_u(), make_lut_v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YUV = cv2.cvtColor(RGB, cv2.COLOR_RGB2YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, U, V = cv2.split(YUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = cv2.cvtColor(Y, cv2.COLOR_GRAY2BGR)\n",
    "U = cv2.cvtColor(U, cv2.COLOR_GRAY2BGR)\n",
    "V = cv2.cvtColor(V, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_mapped = cv2.LUT(U, lut_U)\n",
    "V_mapped = cv2.LUT(V, lut_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,16))\n",
    "\n",
    "a = fig.add_subplot(1,3,1) # Rows, cols, subfigure\n",
    "Y_histo = np.histogram(Y, bins=256)[0]\n",
    "Y_entropy = entropy(Y_histo, base=2)\n",
    "a.set_title(\"entropy(Y') = \" + str(Y_entropy))\n",
    "imgplot = plt.imshow(Y)\n",
    "\n",
    "a = fig.add_subplot(1,3,2)\n",
    "U_histo = np.histogram(U, bins=256)[0]\n",
    "U_entropy = entropy(U_histo, base=2)\n",
    "a.set_title(\"entropy(U) = \" + str(U_entropy))\n",
    "imgplot = plt.imshow(U_mapped)\n",
    "\n",
    "a = fig.add_subplot(1,3,3)\n",
    "V_histo = np.histogram(V, bins=256)[0]\n",
    "V_entropy = entropy(V_histo, base=2)\n",
    "a.set_title(\"entropy(V) = \" + str(V_entropy))\n",
    "imgplot = plt.imshow(V_mapped)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total entropy = {}'.format(Y_entropy + U_entropy + V_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histr = [None for com in components]\n",
    "for i,com in enumerate(components):\n",
    "    histr[i] = cv2.calcHist([YUV],[i],None,[256],[0,256])\n",
    "    plt.plot(histr[i], color = com)\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chrominance subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The human visual system is more sensitive to the luma (Y’) than to the chroma (UV)](https://en.wikipedia.org/wiki/Chroma_subsampling). This means than the chroma can be subsampled without a signiﬁcant loss of quality in the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd 00-fundamentals/\n",
    "!fig2dev -L svg -m 4 color_subsampling.fig > color_subsampling.svg\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/color_subsampling.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_chroma(image, levels):\n",
    "    subsampled = np.ndarray((image.shape[0], image.shape[1], 3), 'uint8')\n",
    "    \n",
    "    # Luma\n",
    "    subsampled[:,:,0] = image[:,:,0]\n",
    "\n",
    "    # Chroma Cb\n",
    "    DWT_coeffs = pywt.wavedec2(image[:,:,1], 'bior3.5', level=levels)\n",
    "    for i in range(levels-1):\n",
    "        DWT_coeffs[i+1][0][:,:] = 0.0 # LH subband\n",
    "        DWT_coeffs[i+1][1][:,:] = 0.0 # HL subband\n",
    "        DWT_coeffs[i+1][2][:,:] = 0.0 # HH subband\n",
    "\n",
    "    subsampled[:,:,1] = pywt.waverec2(DWT_coeffs, 'bior3.5')\n",
    "                  \n",
    "    # Chroma Cb\n",
    "    DWT_coeffs = pywt.wavedec2(image[:,:,2], 'bior3.5', level=levels)\n",
    "    for i in range(levels-1):\n",
    "        DWT_coeffs[i+1][0][:,:] = 0.0 # LH subband\n",
    "        DWT_coeffs[i+1][1][:,:] = 0.0 # HL subband\n",
    "        DWT_coeffs[i+1][2][:,:] = 0.0 # HH subband\n",
    "    subsampled[:,:,2] = pywt.waverec2(DWT_coeffs, 'bior3.5')\n",
    "\n",
    "    return (subsampled, (subsampled.shape[0], subsampled.shape[1]), DWT_coeffs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_subsampled_YUV, luma_shape, chroma_shape = subsample_chroma(YUV, 5)\n",
    "print(\"Luma shape =\", luma_shape, \"\\nChroma shape =\", chroma_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,16))\n",
    "\n",
    "a = fig.add_subplot(1,3,1) # Rows, cols, subfigure\n",
    "a.set_title(\"Y\")\n",
    "imgplot = plt.imshow(chroma_subsampled_YUV[:,:,0], cmap='gray')\n",
    "\n",
    "a = fig.add_subplot(1,3,2)\n",
    "a.set_title(\"U\")\n",
    "imgplot = plt.imshow(chroma_subsampled_YUV[:,:,1], cmap='gray')\n",
    "\n",
    "a = fig.add_subplot(1,3,3)\n",
    "a.set_title(\"V\")\n",
    "imgplot = plt.imshow(chroma_subsampled_YUV[:,:,2], cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "#plt.imshow(chroma_subsampled_YUV[:,:,1], cmap='gray' # Shows U\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_subsampled_RGB = cv2.cvtColor(chroma_subsampled_YUV, cv2.COLOR_YUV2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24,16))\n",
    "\n",
    "a = fig.add_subplot(1,2,1) # Rows, cols, subfigure\n",
    "plt.imshow(RGB)\n",
    "\n",
    "a = fig.add_subplot(1,2,2) # Rows, cols, subfigure\n",
    "plt.imshow(chroma_subsampled_RGB)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The subsampled image uses\", \\\n",
    "      luma_shape[0]*luma_shape[1] +\n",
    "      chroma_shape[0]*chroma_shape[1] * 2,\n",
    "      \"bytes\"\n",
    "     )\n",
    "print(\"The original image uses\", \\\n",
    "      luma_shape[0]*luma_shape[1] * 3,\n",
    "      \"bytes\"\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCT (Discrete Cosine Transform)\n",
    "\n",
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forward (direct) transform:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\text{DCT}[u] = \\frac{\\sqrt{2}}{\\sqrt{N}}\n",
    "  K(u)\\sum_{n=0}^{N-1} s[n]\\cos\\frac{(2n+1)\\pi u}{2n},\n",
    "\\end{equation}\n",
    "\n",
    "backward (inverse) transform:\n",
    "\n",
    "\\begin{equation}\n",
    "  s[n] = \\frac{\\sqrt{2}}{\\sqrt{N}}\n",
    "  \\sum_{u=0}^{N-1} K(u)\\text{DCT}[u]\\cos\\frac{(2n+1)\\pi u}{2n},\n",
    "\\end{equation}\n",
    "\n",
    "where $N$ is the number of pixels, and $s[n]$ denotes the $n$-th pixel\n",
    "of the image $s$, and\n",
    "\n",
    "\\begin{equation}\n",
    "  K(u) =\n",
    "  \\left\\{\n",
    "    \\begin{array}{ll}\n",
    "      \\frac{1}{\\sqrt{2}} & \\text{si}~u=0\\\\\n",
    "      1 & \\text{if}~u>0.\n",
    "    \\end{array}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "\n",
    "### Properties\n",
    "\n",
    "1. **Separable**: the $D$-dimensional DCT can be computed using the $1$D DCT in each possible dimension.\n",
    "2. In general, **high energy compaction**: a small number of DCT coefficients can reconstruct with a reasonable accuracy the original signal.\n",
    "3. **Unitary**: the energy of the DCT coefficients is proportional to the energy of the samples.\n",
    "4. **Orthonormality**: DCT basis are orthonormal (orthogonal + unitary) and therefore, DCT coefficients are uncorrelated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load lena\n",
    "\n",
    "import urllib.request\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "HTTP_response = urllib.request.urlopen('http://www.hpca.ual.es/~vruiz/images/lena.png')\n",
    "arr = np.asarray(bytearray(HTTP_response.read()), dtype=np.uint8)\n",
    "BRG = cv2.imdecode(arr,-1)\n",
    "RGB = cv2.cvtColor(BRG, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "from PIL import Image\n",
    "\n",
    "# Forward and backward DCT wrappers\n",
    "\n",
    "def forward_2d_dct(img):\n",
    "    \"\"\" Get 2D Cosine Transform of Image\n",
    "    \"\"\"\n",
    "    return fftpack.dct(fftpack.dct(img.T, norm='ortho').T, norm='ortho')\n",
    "\n",
    "def inverse_2d_dct(coefficients):\n",
    "    \"\"\" Get 2D Inverse Cosine Transform of Image\n",
    "    \"\"\"\n",
    "    return fftpack.idct(fftpack.idct(coefficients.T, norm='ortho').T, norm='ortho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color 2D-DCT is the 2D-DCT of each component\n",
    "components = ('r','g','b')\n",
    "dct = [None]*3\n",
    "for i,com in enumerate(components):\n",
    "    print(\"{} \".format(i), end='')\n",
    "    dct[i] = forward_2d_dct(RGB[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View DCT coefs\n",
    "view_dct = np.empty(RGB.shape)\n",
    "for i,com in enumerate(components):\n",
    "    view_dct[:,:,i] = dct[i][:,:]\n",
    "plt.imshow((view_dct - view_dct.min())/(view_dct.max() - view_dct.min())*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct with biggest DCT coefs\n",
    "N = 100 # Step size (in coeffs) for each reconstruction\n",
    "for k in range(32):\n",
    "    \n",
    "    coefs_indexes = np.empty((RGB.shape[0] * RGB.shape[1]), dtype='float, int, int')\n",
    "    for i in range(RGB.shape[0]):\n",
    "        for j in range(RGB.shape[1]):\n",
    "            coefs_indexes[i*RGB.shape[1]+j] = (np.abs(dct[0][i][j]), i, j)\n",
    "            \n",
    "    sorted = np.sort(coefs_indexes, axis = -1)[::-1]\n",
    "    \n",
    "    x_coords = np.empty((k+1)*N, dtype='int')\n",
    "    y_coords = np.empty((k+1)*N, dtype='int')\n",
    "    for kk in range((k+1)*N):\n",
    "        x_coords[kk] = sorted[kk][1]\n",
    "        y_coords[kk] = sorted[kk][2]\n",
    "\n",
    "    recons = np.empty(RGB.shape)\n",
    "    \n",
    "    dct_copy = np.zeros(dct[0].shape)\n",
    "\n",
    "    dct_copy[x_coords, y_coords] = dct[0][x_coords, y_coords]\n",
    "    recons_ = inverse_2d_dct(dct_copy)\n",
    "    recons[:,:,0] = recons_[:,:].clip(0,255)\n",
    "    \n",
    "    dct_copy = np.empty_like(dct[1])\n",
    "    dct_copy[x_coords, y_coords] = dct[1][x_coords, y_coords]\n",
    "    recons_ = inverse_2d_dct(dct_copy)\n",
    "    recons[:,:,1] = recons_[:,:].clip(0,255)\n",
    "\n",
    "    dct_copy = np.empty_like(dct[2])\n",
    "    dct_copy[x_coords, y_coords] = dct[2][x_coords, y_coords]\n",
    "    recons_ = inverse_2d_dct(dct_copy)\n",
    "    recons[:,:,2] = recons_[:,:].clip(0,255)\n",
    "    \n",
    "    plt.imshow(recons.astype('uint8'))\n",
    "    plt.grid(False);\n",
    "    plt.xticks([]);\n",
    "    plt.yticks([]);\n",
    "    print(\"{} coefficients\".format((k+1)*N), end='')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCT exhibits a bad performance when applied to high resolution images, but locally it works pretty well. For this reason, most DCT-based image/video codecs divide the images in blocks (typically of 8x8 pixels) and apply the DCT to each block, independently. Let's see the basis functions (the synthesys filters) of the 2D-DCT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        dct_copy = np.zeros((8, 8))\n",
    "\n",
    "        dct_copy[i][j] = 1.0\n",
    "        recons = inverse_2d_dct(dct_copy)\n",
    "        \n",
    "        max = recons.max()\n",
    "        min = recons.min()\n",
    "        if(max!=min):\n",
    "            recons = (recons-min)/(max-min)*255\n",
    "\n",
    "        plt.subplot(8, 8, 8*i+j+1)\n",
    "        plt.imshow(recons, cmap=plt.cm.gray)\n",
    "        plt.grid(False);\n",
    "        plt.xticks([]);\n",
    "        plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dyadic DWT (Discrete Wavelet Transform)\n",
    "\n",
    "Key features:\n",
    "\n",
    "1. **High spectral compaction**.\n",
    "2. **Multiresolution representation**: it is easy to recover a reduced version of the original image if only a sub-set of the coeﬃcients is proccesed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filters bank implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/QMF.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Where:\n",
    "\\begin{equation}\n",
    "  S = (\\uparrow^2(L)*s_L) + (\\uparrow^2(H)*s_H)\n",
    "\\end{equation}\n",
    "and\n",
    "\\begin{equation}\n",
    "  \\begin{array}{rcl}\n",
    "    L & = & \\downarrow^2(S*a_L) \\\\\n",
    "    H & = & \\downarrow^2(S*a_H).\n",
    "  \\end{array}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "1. $a_L$ and $a_H$ are the transfer function (the transfer function of a filter is the response of that filter to the unitary impulse function (Dirac's delta))  of a low-pass filter and high-pass filter, respectively, that have been designed to be complementary (ideally, in $L$ we only found the frequencies of $S$ that are not in $H$, and viceversa). When this is true, it is said the we are using a Perfect Reconstruction Quadrature Mirror Filter bank and the DWT is biorthogonal.\n",
    "\n",
    "2. In the wavelet theory, $s_L$ is named the *scale function* and $s_H$ the *mother function* or *wavelet basis function*. The coefficients of $L$ are also knwon as the *scale coeffients* and the coeffcientes of $H$ the *wavelet coefficients* [[Sovic & Sersic, 2012]](https://scholar.google.es/scholar?hl=en&as_sdt=0%2C5&q=Ana+Sovic+and+Damir+Sersic.+Signal+decomposition+methods+for+reducind+drawbacks+of+the+dwt&btnG=).\n",
    "\n",
    "3. $\\downarrow^2(\\cdot)$ and $\\uparrow^2(\\cdot)$ donote the\n",
    "  subsampling and oversampling operations:\n",
    "  \n",
    "  \\begin{equation}\n",
    "    (\\downarrow^2(S))_i = S_{2i}\n",
    "  \\end{equation}\n",
    "  \n",
    "  and\n",
    "  \n",
    "  \\begin{equation}\n",
    "    (\\uparrow^2(S))_i =\n",
    "  \\left\\{\n",
    "  \\begin{array}{ll}\n",
    "    S_{i/2} & \\text{if $i$ if even} \\\\\n",
    "    0 & \\text{otherwise}.\n",
    "  \\end{array}\n",
    "  \\right.\n",
    "  \\end{equation}\n",
    "  \n",
    "  where $S_i$ if the $i$-th sample of $S$.\n",
    "  \n",
    "4. $*$ is the convolution operator.\n",
    "\n",
    "5. Notice that half of the filtered samples are wasted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lifting implementation [[Sweldens & Schröder, 2000)]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=building+wavelets+at+home&btnG=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/lifting.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "1.\n",
    "\\begin{equation}\n",
    "  H_i = S_{2i+1} - {\\cal P}(\\{S_{2i}\\})_i\n",
    "  \\tag{PredictionStep}\n",
    "  \\label{eq:PredictionStep}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  L_i = S_{2i} + \\{{\\cal U}(H)\\}_i\n",
    "  \\tag{UpdateStep}\n",
    "  \\label{eq:UpdateStep}\n",
    "\\end{equation}\n",
    "\n",
    "2. Subsampled signals $\\{S_{2i}\\}$ and $\\{S_{2i+1}\\}$ can been computed by using\n",
    "\n",
    "\\begin{equation*}\n",
    "   \\{S_{2i+1}\\} = \\downarrow^2(Z^{-1}(S))\n",
    "\\end{equation*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation*}\n",
    "   \\{S_{2i}\\} = \\downarrow^2(S),\n",
    "\\end{equation*}\n",
    "\n",
    "where $Z^{-1}$ represents the one sample delay function.\n",
    "\n",
    "3. $H$ has tipically less energy and entropy than $\\{S_{2i+1}\\}$.\n",
    "4. $L$ has less aliasing than $\\{S_{2i}\\}$ (notice that $L$ has not\n",
    "  been low-pass filtered before subsampling it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $T$-levels 1D-DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/n_levels_dwt1d.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2D-DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-dimensional (1D) DWT is a separable transform. Therefore, the 2D DWT can be computed applying the DWT to all the rows of an image and next, to all the columns, or viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/2D-DWT.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contribution of a coefficient of a subband $b$ is determined by the DWT basis fuction ${s_H}^b$ asociated to that coefficient, which can be empirically determined by applying the inverse DWT to the Dirac Impulse function localized in that coefficient (notice that ${s_H}^b$ does not depend on the coefficient because we are supposing that all the coefficients of a subband have the same contribution, the same basis fuction) [[Rabbani, Joshi & Jones, 2009]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=Majid+Rabban%2C+Rajan+L.+Joshi%2C+and+Paul+W.+Jones.+The+JPEG+2000+Suite%2C+chapter+JPEG+2000+Core+Coding+System+%28Part+1%29.+WILEY%2C+2009&btnG=). Therefore, the L$_2$-norm for the subband $b$ is computed as the energy of a basis function of that subband as\n",
    "\n",
    "\\begin{equation}\n",
    "  E({s_H}^b) = \\sum_i{|{s_H}^b_i|}^2.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the 5/3-DWT, the L$_2$-norms of the DWT subbands are:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"00-fundamentals/factores_5_3_L2_norm.svg\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Haar filters [[Haar, 1910]](https://scholar.google.es/scholar?hl=es&as_sdt=0%2C5&q=A.+Haar.+Zur+Theorie+der+orthogolanen+Funktionen-Systeme.+Mathematische+Annalen%2C+69%3A331%E2%80%93371%2C+1910&btnG=)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $i$-th sample of the low-frequency subband is computed (using a filter plus subsampling) as\n",
    "\n",
    "\\begin{equation}\n",
    "  L_i=\\frac{S_{2i}+S_{2i+1}}{2},\n",
    "  \\tag{HaarL}\n",
    "  \\label{eq:Haar_A-LPF}\n",
    "\\end{equation}\n",
    "\n",
    "and the $i$-th sample of the high-frequency subband as\n",
    "\n",
    "\\begin{equation}\n",
    "  H_i=S_{2i+1}-S_{2i}.\n",
    "  \\tag{HaarH}\n",
    "  \\label{eq:Haar_A-HPF}\n",
    "\\end{equation}\n",
    "\n",
    "If Lifting is used,\n",
    "\n",
    "\\begin{equation}\n",
    "  L_i=S_{2i}+\\frac{H_i}{2}.\n",
    "  \\tag{HaarLLifted}\n",
    "  \\label{eq:Haar_A-LPF-lifting}\n",
    "\\end{equation}\n",
    "\n",
    "Notice that $H_i=0$ if $S_{2i+1}=S_{2i}$, therefore, the Haar transform is good to encode constant signals. The notation X/Y indicates the length (taps or number of coefficients) of the low-pass and the high-pass (convolution) filters of the filter bank implementation (not Lifting), respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "\n",
    "fig = plt.figure(figsize=(16, 16))\n",
    "\n",
    "coeffs = np.zeros((512, 512))\n",
    "coeffs[1][1] = 1.0\n",
    "\n",
    "        recons = inverse_2d_dct(dct_copy)\n",
    "        \n",
    "        max = recons.max()\n",
    "        min = recons.min()\n",
    "        if(max!=min):\n",
    "            recons = (recons-min)/(max-min)*255\n",
    "\n",
    "        plt.subplot(8, 8, 8*i+j+1)\n",
    "        plt.imshow(recons, cmap=plt.cm.gray)\n",
    "        plt.grid(False);\n",
    "        plt.xticks([]);\n",
    "        plt.yticks([]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
